

	***************************************************************************		Aggregations	****************************************************************************
	
	The aggregations framework helps provide aggregated data based on a search query. It is based on simple building blocks called aggregations, that can be composed in order to build complex summaries of the data.

	An aggregation can be seen as a unit-of-work that builds analytic information over a set of documents. The context of the execution defines what this document set is (e.g. a top-level aggregation executes within the context of the executed query/filters of the search request).

	There are many different types of aggregations, each with its own purpose and output. To better understand these types, it is often easier to break them into three main families:

	Bucketing
	A family of aggregations that build buckets, where each bucket is associated with a key and a document criterion. When the aggregation is executed, all the buckets criteria are evaluated on every document in the context and when a criterion matches, the document is considered to "fall in" the relevant bucket. By the end of the aggregation process, we’ll end up with a list of buckets - each one with a set of documents that "belong" to it.
	Metric
	Aggregations that keep track and compute metrics over a set of documents.
	Pipeline
	Aggregations that aggregate the output of other aggregations and their associated metrics
	The interesting part comes next. Since each bucket effectively defines a document set (all documents belonging to the bucket), one can potentially associate aggregations on the bucket level, and those will execute within the context of that bucket. This is where the real power of aggregations kicks in: aggregations can be nested!

	Note
	Bucketing aggregations can have sub-aggregations (bucketing or metric). The sub-aggregations will be computed for the buckets which their parent aggregation generates. There is no hard limit on the level/depth of nested aggregations (one can nest an aggregation under a "parent" aggregation, which is itself a sub-aggregation of another higher-level aggregation).

	Structuring Aggregationsedit
	The following snippet captures the basic structure of aggregations:

		"aggregations" : {
			"<aggregation_name>" : {
				"<aggregation_type>" : {
					<aggregation_body>
				}
				[,"meta" : {  [<meta_data_body>] } ]?
				[,"aggregations" : { [<sub_aggregation>]+ } ]?
			}
			[,"<aggregation_name_2>" : { ... } ]*
		}
	The aggregations object (the key aggs can also be used) in the JSON holds the aggregations to be computed. Each aggregation is associated with a logical name that the user defines (e.g. if the aggregation computes the average price, then it would make sense to name it avg_price). These logical names will also be used to uniquely identify the aggregations in the response. Each aggregation has a specific type (<aggregation_type> in the above snippet) and is typically the first key within the named aggregation body. Each type of aggregation defines its own body, depending on the nature of the aggregation (e.g. an avg aggregation on a specific field will define the field on which the average will be calculated). At the same level of the aggregation type definition, one can optionally define a set of additional aggregations, though this only makes sense if the aggregation you defined is of a bucketing nature. In this scenario, the sub-aggregations you define on the bucketing aggregation level will be computed for all the buckets built by the bucketing aggregation. For example, if you define a set of aggregations under the range aggregation, the sub-aggregations will be computed for the range buckets that are defined.
		
	*********************************************************************************************************************************************************************************************
	
													  Metrics Aggregations
													  
	Numeric metrics aggregations are a special type of metrics aggregation which output numeric values. Some aggregations output a single numeric metric (e.g. avg) and are called "single-value" numeric metrics aggregation, others generate multiple metrics (e.g. stats) and are called "multi-value" numeric metrics aggregation. The distinction between single-value and multi-value numeric metrics aggregations plays a role when these aggregations serve as direct sub-aggregations of some bucket aggregations (some bucket aggregations enable you to sort the returned buckets based on the numeric metrics in each bucket).

	1) Avg aggregation
		A single-value metrics aggregation that computes the average of numeric values that are extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.

		Assuming the data consists of documents representing exams grades (between 0 and 100) of students
			{
					"avg_grade" : { "avg" : { "field" : "grade" } }
				"aggs" : {
				}
			}
		The above aggregation computes the average grade over all documents. The aggregation type is avg and the field setting defines the numeric field of the documents the average will be computed on. 
													  
	2) Cardinality Aggregation
		A single-value metrics aggregation that calculates an approximate count of distinct values. Values can be extracted either from specific fields in the document or generated by a script.
		Assume you are indexing books and would like to count the unique authors that match a query:

			{
				"aggs" : {
					"author_count" : {
						"cardinality" : {
							"field" : "author"
						}
					}
				}
			}
	
	3) Max Aggregation
		A single-value metrics aggregation that keeps track and returns the maximum value among the numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.

		Computing the max price value across all documents
			{
				"aggs" : {
					"max_price" : { "max" : { "field" : "price" } }
				}
			}
		
		Response:
			{
				...

				"aggregations": {
					"max_price": {
						"value": 35
					}
				}
			}
		
	4) Min Aggregation
		A single-value metrics aggregation that keeps track and returns the minimum value among numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.

		Computing the min price value across all documents:
			{
				"aggs" : {
					"min_price" : { "min" : { "field" : "price" } }
				}
			}
		Response:
			{
				...

				"aggregations": {
					"min_price": {
						"value": 10
					}
				}
			}
			
	5) Percentiles Aggregation
		A multi-value metrics aggregation that calculates one or more percentiles over numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.

		Percentiles show the point at which a certain percentage of observed values occur. For example, the 95th percentile is the value which is greater than 95% of the observed values.

		Percentiles are often used to find outliers. In normal distributions, the 0.13th and 99.87th percentiles represents three standard deviations from the mean. Any data which falls outside three standard deviations is often considered an anomaly.

		When a range of percentiles are retrieved, they can be used to estimate the data distribution and determine if the data is skewed, bimodal, etc.

		Assume your data consists of website load times. The average and median load times are not overly useful to an administrator. The max may be interesting, but it can be easily skewed by a single slow response.

		Let’s look at a range of percentiles representing load time:
			{
				"aggs" : {
					"load_time_outlier" : {
						"percentiles" : {
							"field" : "load_time" 
						}
					}
				}
			}


		The field load_time must be a numeric field

		By default, the percentile metric will generate a range of percentiles: [ 1, 5, 25, 50, 75, 95, 99 ]. The response will look like this:
		{
			...

		   "aggregations": {
			  "load_time_outlier": {
				 "values" : {
					"1.0": 15,
					"5.0": 20,
					"25.0": 23,
					"50.0": 25,
					"75.0": 29,
					"95.0": 60,
					"99.0": 150
				 }
			  }
		   }
		}
	6) Stats Aggregation
		A multi-value metrics aggregation that computes stats over numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.

		The stats that are returned consist of: min, max, sum, count and avg.
		Assuming the data consists of documents representing exams grades (between 0 and 100) of students
			{
				"aggs" : {
					"grades_stats" : { "stats" : { "field" : "grade" } }
				}
			}
		The above aggregation computes the grades statistics over all documents. The aggregation type is stats and the field setting defines the numeric field of the documents the stats will be computed on.
	7) Value Count Aggregation
		A single-value metrics aggregation that counts the number of values that are extracted from the aggregated documents. These values can be extracted either from specific fields in the documents, or be generated by a provided script. Typically, this aggregator will be used in conjunction with other single-value aggregations. For example, when computing the avg one might be interested in the number of values the average is computed over.
			{
				"aggs" : {
					"grades_count" : { "value_count" : { "field" : "grade" } }
				}
			}
			
	8) 